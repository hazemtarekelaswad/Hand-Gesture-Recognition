{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper functions for models-comparison\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, auc, confusion_matrix\n",
    "\n",
    "\n",
    "def get_metrics(y_true, y_pred, print_metrics=True):\n",
    "    \"\"\"\n",
    "    Get accuracy, precision, recall, f1-score, auc, confusion matrix\n",
    "    \"\"\"\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    prec = precision_score(y_true, y_pred, average='weighted')\n",
    "    rec = recall_score(y_true, y_pred, average='weighted')\n",
    "    f1 = f1_score(y_true, y_pred, average='weighted')\n",
    "    conf_mat = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "    if print_metrics:\n",
    "        print('Accuracy: {:.2f}'.format(acc*100))\n",
    "        print('Precision: {:.2f}'.format(prec))\n",
    "        print('Recall: {:.2f}'.format(rec))\n",
    "        print('F1-score: {:.2f}'.format(f1))\n",
    "        print('Confusion matrix:')\n",
    "        print(pd.DataFrame(conf_mat))\n",
    "\n",
    "    return acc, prec, rec, f1, conf_mat\n",
    "\n",
    "\n",
    "# take the model and the train and test data and return the metrics\n",
    "def get_metrics_model(model, X_train, y_train, X_test, y_test, print_metrics=True):\n",
    "    \"\"\"\n",
    "    Get accuracy, precision, recall, f1-score, auc, confusion matrix\n",
    "    \"\"\"\n",
    "    # get model name\n",
    "    if print_metrics:\n",
    "       print(\"training model: {}\".format(model.__class__.__name__))\n",
    "    model.fit(X_train, y_train)\n",
    "    if print_metrics:\n",
    "        print(\"predicting model: {}\".format(model.__class__.__name__))\n",
    "    y_pred = model.predict(X_test)\n",
    "    if print_metrics:\n",
    "        print(\"evaluating model: {}\".format(model.__class__.__name__))\n",
    "    acc, prec, rec, f1, conf_mat = get_metrics(y_test, y_pred, print_metrics)\n",
    "\n",
    "    if print_metrics:\n",
    "        print('saving model: {}'.format(model.__class__.__name__))\n",
    "    \n",
    "    # # save the trained model\n",
    "    # model_name = model.__class__.__name__\n",
    "    # model.save('models/{}.h5'.format(model_name))\n",
    "\n",
    "    return acc, prec, rec, f1, conf_mat\n",
    "\n",
    "\n",
    "# compute the metrics for all the models and return a dataframe with the results\n",
    "def get_metrics_all_models(models, X_train, y_train, X_test, y_test):\n",
    "    \"\"\"\n",
    "    Get accuracy, precision, recall, f1-score, auc, confusion matrix for all models\n",
    "    \"\"\"\n",
    "    metrics = []\n",
    "    for model in models:\n",
    "        print('Model: {}'.format(model.__class__.__name__))\n",
    "        acc, prec, rec, f1, conf_mat = get_metrics_model(model, X_train, y_train, X_test, y_test, print_metrics=False)\n",
    "        metrics.append([acc, prec, rec, f1, conf_mat])\n",
    "\n",
    "    df_metrics = pd.DataFrame(metrics, columns=['Accuracy', 'Precision', 'Recall', 'F1-score', 'Confusion matrix'])\n",
    "    df_metrics.index = [str(model) for model in models]\n",
    "\n",
    "    return df_metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size:  800\n",
      "Testing set size:  200\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# Define the number of samples and features\n",
    "num_samples = 1000\n",
    "num_features = 6\n",
    "# Create a random feature matrix\n",
    "X = np.random.rand(num_samples, num_features)\n",
    "# Create corresponding labels 6 classes (0, 1, 2, 3, 4, 5)\n",
    "Y = np.random.randint(6, size=num_samples)\n",
    "\n",
    "# split the data into training (80%) and testing (20%) sets\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "# check the size of the training and testing sets\n",
    "print(\"Training set size: \", X_train.shape[0])\n",
    "print(\"Testing set size: \", X_test.shape[0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# - Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import  GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "models = [svm.SVC(kernel='linear'), RandomForestClassifier(n_estimators=1), KNeighborsClassifier(n_neighbors=14),DecisionTreeClassifier(max_depth=3), GaussianNB(),\n",
    "          LogisticRegression(), GradientBoostingClassifier(n_estimators=100, learning_rate=.1, max_depth=3, random_state=0), AdaBoostClassifier(n_estimators=1000, random_state=0), \n",
    "          ExtraTreesClassifier(n_estimators=1, random_state=0), XGBClassifier(n_estimators=1000, learning_rate=0.008, max_depth=3, random_state=0)]\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear SVM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training model: SVC\n",
      "predicting model: SVC\n",
      "evaluating model: SVC\n",
      "Accuracy: 17.50\n",
      "Precision: 0.15\n",
      "Recall: 0.17\n",
      "F1-score: 0.14\n",
      "Confusion matrix:\n",
      "   0   1  2   3  4   5\n",
      "0  1  12  8  10  1   5\n",
      "1  0  11  5  11  1   4\n",
      "2  0   8  4   7  1   5\n",
      "3  0   9  6  13  0   6\n",
      "4  1  10  3   5  0  10\n",
      "5  3  12  9  13  0   6\n"
     ]
    }
   ],
   "source": [
    "acc, prec, rec, f1, conf_mat = get_metrics_model(models[0], X_train, Y_train, X_test, Y_test)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training model: RandomForestClassifier\n",
      "predicting model: RandomForestClassifier\n",
      "evaluating model: RandomForestClassifier\n",
      "Accuracy: 17.00\n",
      "Precision: 0.18\n",
      "Recall: 0.17\n",
      "F1-score: 0.17\n",
      "Confusion matrix:\n",
      "   0  1  2  3  4   5\n",
      "0  6  4  5  4  9   9\n",
      "1  3  6  2  7  3  11\n",
      "2  1  8  2  5  5   4\n",
      "3  3  5  6  7  7   6\n",
      "4  2  7  3  3  5   9\n",
      "5  5  5  7  9  9   8\n"
     ]
    }
   ],
   "source": [
    "acc, prec, rec, f1, conf_mat = get_metrics_model(models[1], X_train, Y_train, X_test, Y_test) # check n_estimators, max_depth, random_state\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training model: KNeighborsClassifier\n",
      "predicting model: KNeighborsClassifier\n",
      "evaluating model: KNeighborsClassifier\n",
      "Accuracy: 21.00\n",
      "Precision: 0.21\n",
      "Recall: 0.21\n",
      "F1-score: 0.21\n",
      "Confusion matrix:\n",
      "    0   1  2   3  4  5\n",
      "0   4   8  5   9  9  2\n",
      "1   2   7  7   5  4  7\n",
      "2   5   6  4   4  2  4\n",
      "3   6   5  4  14  3  2\n",
      "4   4   6  6   2  7  4\n",
      "5  10  12  5   7  3  6\n"
     ]
    }
   ],
   "source": [
    "acc, prec, rec, f1, conf_mat = get_metrics_model(models[2], X_train, Y_train, X_test, Y_test) # check n_neighbors\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training model: DecisionTreeClassifier\n",
      "predicting model: DecisionTreeClassifier\n",
      "evaluating model: DecisionTreeClassifier\n",
      "Accuracy: 18.00\n",
      "Precision: 0.31\n",
      "Recall: 0.18\n",
      "F1-score: 0.09\n",
      "Confusion matrix:\n",
      "   0   1  2  3  4  5\n",
      "0  0  32  0  5  0  0\n",
      "1  0  31  1  0  0  0\n",
      "2  0  23  1  1  0  0\n",
      "3  0  31  0  3  0  0\n",
      "4  0  28  1  0  0  0\n",
      "5  0  38  2  2  0  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\saif8\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "acc, prec, rec, f1, conf_mat = get_metrics_model(models[3], X_train, Y_train, X_test, Y_test) # check max_depth, random_state\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training model: GaussianNB\n",
      "predicting model: GaussianNB\n",
      "evaluating model: GaussianNB\n",
      "Accuracy: 15.50\n",
      "Precision: 0.14\n",
      "Recall: 0.15\n",
      "F1-score: 0.14\n",
      "Confusion matrix:\n",
      "   0   1  2   3  4   5\n",
      "0  2  16  5   6  2   6\n",
      "1  0   9  7   9  2   5\n",
      "2  1   7  4   5  1   7\n",
      "3  1   9  8  11  0   5\n",
      "4  2   8  3   6  0  10\n",
      "5  6  12  8   7  5   5\n"
     ]
    }
   ],
   "source": [
    "acc, prec, rec, f1, conf_mat = get_metrics_model(models[4], X_train, Y_train, X_test, Y_test) \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training model: LogisticRegression\n",
      "predicting model: LogisticRegression\n",
      "evaluating model: LogisticRegression\n",
      "Accuracy: 17.50\n",
      "Precision: 0.18\n",
      "Recall: 0.17\n",
      "F1-score: 0.16\n",
      "Confusion matrix:\n",
      "   0   1  2   3  4  5\n",
      "0  2  11  7   8  3  6\n",
      "1  0  10  7  10  2  3\n",
      "2  0   8  4   5  2  6\n",
      "3  0   6  7  13  1  7\n",
      "4  1  11  3   4  1  9\n",
      "5  4  13  8  10  3  5\n"
     ]
    }
   ],
   "source": [
    "acc, prec, rec, f1, conf_mat = get_metrics_model(models[5], X_train, Y_train, X_test, Y_test)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training model: GradientBoostingClassifier\n",
      "predicting model: GradientBoostingClassifier\n",
      "evaluating model: GradientBoostingClassifier\n",
      "Accuracy: 17.50\n",
      "Precision: 0.18\n",
      "Recall: 0.17\n",
      "F1-score: 0.18\n",
      "Confusion matrix:\n",
      "   0  1  2   3  4   5\n",
      "0  4  7  6   9  7   4\n",
      "1  3  7  6  11  1   4\n",
      "2  4  6  4   7  1   3\n",
      "3  3  9  4   5  4   9\n",
      "4  3  7  3   7  4   5\n",
      "5  6  6  7   7  6  11\n"
     ]
    }
   ],
   "source": [
    "acc, prec, rec, f1, conf_mat = get_metrics_model(models[6], X_train, Y_train, X_test, Y_test) # check n_estimators, learning_rate, max_depth, random_state\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training model: AdaBoostClassifier\n",
      "predicting model: AdaBoostClassifier\n",
      "evaluating model: AdaBoostClassifier\n",
      "Accuracy: 16.50\n",
      "Precision: 0.17\n",
      "Recall: 0.17\n",
      "F1-score: 0.16\n",
      "Confusion matrix:\n",
      "   0   1  2  3  4   5\n",
      "0  7   6  3  6  8   7\n",
      "1  2   9  1  7  3  10\n",
      "2  5   5  4  5  2   4\n",
      "3  3   6  3  6  5  11\n",
      "4  5  10  3  7  1   3\n",
      "5  8   8  5  8  8   6\n"
     ]
    }
   ],
   "source": [
    "acc, prec, rec, f1, conf_mat = get_metrics_model(models[7], X_train, Y_train, X_test, Y_test) # check n_estimators, random_state\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extra Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training model: ExtraTreesClassifier\n",
      "predicting model: ExtraTreesClassifier\n",
      "evaluating model: ExtraTreesClassifier\n",
      "Accuracy: 19.00\n",
      "Precision: 0.20\n",
      "Recall: 0.19\n",
      "F1-score: 0.19\n",
      "Confusion matrix:\n",
      "   0   1   2  3  4  5\n",
      "0  7  13   5  4  4  4\n",
      "1  3  12   3  4  5  5\n",
      "2  4   5   3  4  6  3\n",
      "3  5   7   7  5  4  6\n",
      "4  4   7   5  4  5  4\n",
      "5  5   5  17  4  6  6\n"
     ]
    }
   ],
   "source": [
    "acc, prec, rec, f1, conf_mat = get_metrics_model(models[8], X_train, Y_train, X_test, Y_test) # check n_estimators, random_state\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training model: XGBClassifier\n",
      "predicting model: XGBClassifier\n",
      "evaluating model: XGBClassifier\n",
      "Accuracy: 20.50\n",
      "Precision: 0.21\n",
      "Recall: 0.20\n",
      "F1-score: 0.20\n",
      "Confusion matrix:\n",
      "   0  1  2   3  4   5\n",
      "0  5  8  6  11  5   2\n",
      "1  4  9  6   6  3   4\n",
      "2  1  7  6   7  2   2\n",
      "3  2  8  2   7  6   9\n",
      "4  5  8  3   4  3   6\n",
      "5  8  8  8   6  2  11\n"
     ]
    }
   ],
   "source": [
    "acc, prec, rec, f1, conf_mat = get_metrics_model(models[9], X_train, Y_train, X_test, Y_test) # check n_estimators, learning_rate, max_depth, random_state\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: SVC\n",
      "Model: RandomForestClassifier\n",
      "Model: KNeighborsClassifier\n",
      "Model: DecisionTreeClassifier\n",
      "Model: GaussianNB\n",
      "Model: LogisticRegression\n",
      "Model: GradientBoostingClassifier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\saif8\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: AdaBoostClassifier\n",
      "Model: ExtraTreesClassifier\n",
      "Model: XGBClassifier\n"
     ]
    }
   ],
   "source": [
    "df_metrics = get_metrics_all_models(models, X_train, Y_train, X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1-score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>SVC(kernel='linear')</th>\n",
       "      <td>0.175</td>\n",
       "      <td>0.152964</td>\n",
       "      <td>0.175</td>\n",
       "      <td>0.143108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestClassifier(n_estimators=1)</th>\n",
       "      <td>0.150</td>\n",
       "      <td>0.155626</td>\n",
       "      <td>0.150</td>\n",
       "      <td>0.151507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNeighborsClassifier(n_neighbors=14)</th>\n",
       "      <td>0.210</td>\n",
       "      <td>0.211353</td>\n",
       "      <td>0.210</td>\n",
       "      <td>0.206117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTreeClassifier(max_depth=3)</th>\n",
       "      <td>0.180</td>\n",
       "      <td>0.313467</td>\n",
       "      <td>0.180</td>\n",
       "      <td>0.086912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GaussianNB()</th>\n",
       "      <td>0.155</td>\n",
       "      <td>0.139515</td>\n",
       "      <td>0.155</td>\n",
       "      <td>0.137228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LogisticRegression()</th>\n",
       "      <td>0.175</td>\n",
       "      <td>0.180009</td>\n",
       "      <td>0.175</td>\n",
       "      <td>0.155284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GradientBoostingClassifier(random_state=0)</th>\n",
       "      <td>0.175</td>\n",
       "      <td>0.184897</td>\n",
       "      <td>0.175</td>\n",
       "      <td>0.176550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AdaBoostClassifier(n_estimators=1000, random_state=0)</th>\n",
       "      <td>0.165</td>\n",
       "      <td>0.165197</td>\n",
       "      <td>0.165</td>\n",
       "      <td>0.163117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ExtraTreesClassifier(n_estimators=1, random_state=0)</th>\n",
       "      <td>0.190</td>\n",
       "      <td>0.199047</td>\n",
       "      <td>0.190</td>\n",
       "      <td>0.188520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBClassifier(base_score=None, booster=None, callbacks=None,\\n              colsample_bylevel=None, colsample_bynode=None,\\n              colsample_bytree=None, early_stopping_rounds=None,\\n              enable_categorical=False, eval_metric=None, feature_types=None,\\n              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\\n              interaction_constraints=None, learning_rate=0.008, max_bin=None,\\n              max_cat_threshold=None, max_cat_to_onehot=None,\\n              max_delta_step=None, max_depth=3, max_leaves=None,\\n              min_child_weight=None, missing=nan, monotone_constraints=None,\\n              n_estimators=1000, n_jobs=None, num_parallel_tree=None,\\n              objective='multi:softprob', predictor=None, ...)</th>\n",
       "      <td>0.205</td>\n",
       "      <td>0.210491</td>\n",
       "      <td>0.205</td>\n",
       "      <td>0.203186</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    Accuracy  Precision  \\\n",
       "SVC(kernel='linear')                                   0.175   0.152964   \n",
       "RandomForestClassifier(n_estimators=1)                 0.150   0.155626   \n",
       "KNeighborsClassifier(n_neighbors=14)                   0.210   0.211353   \n",
       "DecisionTreeClassifier(max_depth=3)                    0.180   0.313467   \n",
       "GaussianNB()                                           0.155   0.139515   \n",
       "LogisticRegression()                                   0.175   0.180009   \n",
       "GradientBoostingClassifier(random_state=0)             0.175   0.184897   \n",
       "AdaBoostClassifier(n_estimators=1000, random_st...     0.165   0.165197   \n",
       "ExtraTreesClassifier(n_estimators=1, random_sta...     0.190   0.199047   \n",
       "XGBClassifier(base_score=None, booster=None, ca...     0.205   0.210491   \n",
       "\n",
       "                                                    Recall  F1-score  \n",
       "SVC(kernel='linear')                                 0.175  0.143108  \n",
       "RandomForestClassifier(n_estimators=1)               0.150  0.151507  \n",
       "KNeighborsClassifier(n_neighbors=14)                 0.210  0.206117  \n",
       "DecisionTreeClassifier(max_depth=3)                  0.180  0.086912  \n",
       "GaussianNB()                                         0.155  0.137228  \n",
       "LogisticRegression()                                 0.175  0.155284  \n",
       "GradientBoostingClassifier(random_state=0)           0.175  0.176550  \n",
       "AdaBoostClassifier(n_estimators=1000, random_st...   0.165  0.163117  \n",
       "ExtraTreesClassifier(n_estimators=1, random_sta...   0.190  0.188520  \n",
       "XGBClassifier(base_score=None, booster=None, ca...   0.205  0.203186  "
      ]
     },
     "execution_count": 332,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print the metrics for all the models in a dataframe format excluding the confusion matrix\n",
    "df_metrics.drop('Confusion matrix', axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: SVC\n",
      "[[ 1 12  8 10  1  5]\n",
      " [ 0 11  5 11  1  4]\n",
      " [ 0  8  4  7  1  5]\n",
      " [ 0  9  6 13  0  6]\n",
      " [ 1 10  3  5  0 10]\n",
      " [ 3 12  9 13  0  6]]\n",
      "\n",
      "Model: RandomForestClassifier\n",
      "[[ 4  7  9 10  3  4]\n",
      " [ 6  4  2  9  4  7]\n",
      " [ 5  2  4  7  6  1]\n",
      " [ 6  2  6  6  6  8]\n",
      " [ 8  5  3  4  4  5]\n",
      " [10 11  4  7  3  8]]\n",
      "\n",
      "Model: KNeighborsClassifier\n",
      "[[ 4  8  5  9  9  2]\n",
      " [ 2  7  7  5  4  7]\n",
      " [ 5  6  4  4  2  4]\n",
      " [ 6  5  4 14  3  2]\n",
      " [ 4  6  6  2  7  4]\n",
      " [10 12  5  7  3  6]]\n",
      "\n",
      "Model: DecisionTreeClassifier\n",
      "[[ 0 32  0  5  0  0]\n",
      " [ 0 31  1  0  0  0]\n",
      " [ 0 23  1  1  0  0]\n",
      " [ 0 31  0  3  0  0]\n",
      " [ 0 28  1  0  0  0]\n",
      " [ 0 38  2  2  0  1]]\n",
      "\n",
      "Model: GaussianNB\n",
      "[[ 2 16  5  6  2  6]\n",
      " [ 0  9  7  9  2  5]\n",
      " [ 1  7  4  5  1  7]\n",
      " [ 1  9  8 11  0  5]\n",
      " [ 2  8  3  6  0 10]\n",
      " [ 6 12  8  7  5  5]]\n",
      "\n",
      "Model: LogisticRegression\n",
      "[[ 2 11  7  8  3  6]\n",
      " [ 0 10  7 10  2  3]\n",
      " [ 0  8  4  5  2  6]\n",
      " [ 0  6  7 13  1  7]\n",
      " [ 1 11  3  4  1  9]\n",
      " [ 4 13  8 10  3  5]]\n",
      "\n",
      "Model: GradientBoostingClassifier\n",
      "[[ 4  7  6  9  7  4]\n",
      " [ 3  7  6 11  1  4]\n",
      " [ 4  6  4  7  1  3]\n",
      " [ 3  9  4  5  4  9]\n",
      " [ 3  7  3  7  4  5]\n",
      " [ 6  6  7  7  6 11]]\n",
      "\n",
      "Model: AdaBoostClassifier\n",
      "[[ 7  6  3  6  8  7]\n",
      " [ 2  9  1  7  3 10]\n",
      " [ 5  5  4  5  2  4]\n",
      " [ 3  6  3  6  5 11]\n",
      " [ 5 10  3  7  1  3]\n",
      " [ 8  8  5  8  8  6]]\n",
      "\n",
      "Model: ExtraTreesClassifier\n",
      "[[ 7 13  5  4  4  4]\n",
      " [ 3 12  3  4  5  5]\n",
      " [ 4  5  3  4  6  3]\n",
      " [ 5  7  7  5  4  6]\n",
      " [ 4  7  5  4  5  4]\n",
      " [ 5  5 17  4  6  6]]\n",
      "\n",
      "Model: XGBClassifier\n",
      "[[ 5  8  6 11  5  2]\n",
      " [ 4  9  6  6  3  4]\n",
      " [ 1  7  6  7  2  2]\n",
      " [ 2  8  2  7  6  9]\n",
      " [ 5  8  3  4  3  6]\n",
      " [ 8  8  8  6  2 11]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# print the confusion matrix for all the models in a table format\n",
    "for i in range(len(models)):\n",
    "    print('Model: {}'.format(models[i].__class__.__name__))\n",
    "    print(df_metrics.iloc[i]['Confusion matrix'])\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
